> 文章可以白嫖，老铁们顺便关注一下我的公众号，手动滑稽🤣🤣 &nbsp;
>
> 欢迎大家关注：**武哥聊编程**、**Java开发宝典**、**Java秃头哥**，您的支持，是我创作的持续动力！&nbsp;&nbsp;

![公众号二维码](https://img-blog.csdnimg.cn/20201121225359995.png)

----

# ConcurrentHashMap

众所周知，HashMap在多线程情况下，在put的时候，插入的元素超过了容量（由负载因子决定）的范围就会触发扩容操作；若存在同时其他的元素也在进行put操作，如果hash值相同，可能出现同时在同一数组下用链表表示，造成闭环，导致在get时会出现死循环，所以HashMap是线程不安全的。那么今天我们就来了解下线程安全的 `ConcurrentHashmap  `。

## 数据结构

![image](http://note.youdao.com/yws/public/resource/07a596690165d28c75671b1363b80262/xmlnote/51850740F400417A9CC44C5F130C5E53/13525)

> 由此可知，`ConcurrentHashMap` 与 `HashMap` 类同，也是由 数组+链表+红黑树 构成。

- Node 实体
> ConcurrentHashMap, key, value, next封装到一个静态内部类 `Node` 上。它 `实现了Map.Entry<K,V>` 接口。

```java
static class Node<K,V> implements Map.Entry<K,V> {
	// hash值
    final int hash;
    // 键
    final K key;
    // 值
    volatile V val;
    // 链表下一个节点
    volatile Node<K,V> next;
    
    // 构造方法
    Node(int hash, K key, V val, Node<K,V> next) {
        this.hash = hash;
        this.key = key;
        this.val = val;
        this.next = next;
    }
    
    // 获取键
    public final K getKey()        { return key; }
    // 获取值
    public final V getValue()      { return val; }
    // 计算hashCode值
    public final int hashCode() {
        return key.hashCode() ^ val.hashCode();
    }
    // 重写toString方法
    public final String toString() { return key + "=" + val; }
    
    // 不允许调用setValue方法直接改变Node的value域
    public final V setValue(V newValue) {
        throw new UnsupportedOperationException();
    }
    // 比较两个entry
    public final boolean equals(Object o) {
        Object k, v, u; Map.Entry<?,?> e;
            return ((o instanceof Map.Entry) &&
                    (k = (e = (Map.Entry<?,?>)o).getKey()) != null &&
                    (v = e.getValue()) != null &&
                    (k == key || k.equals(key)) &&
                    (v == (u = val) || v.equals(u)));
    }
    
    // 根据哈希值以及key 查找对应的节点
    Node<K,V> find(int h, Object k) {
        Node<K,V> e = this;
        if (k != null) {
            do {
                K ek;
                if (e.hash == h &&
                    ((ek = e.key) == k || (ek != null && k.equals(ek))))
                    return e;
            } while ((e = e.next) != null);
        }
        return null;
    }
}
```

**可以看到，这个Node<K,V>[]核心的内部类，它包装了key-value键值对，所有插入ConcurrentHashMap的数据都包装在这里面。它与HashMap中的定义很相似，但是但是有一些差别它对value和next属性设置了 `volatile同步锁` ; `不允许调用setValue方法直接改变Node的value域`，它 `增加了find方法辅助map.get()方法` 。**

## 源码分析

- 成员属性

```
  // node数组最大容量：2^30=1073741824  
  private static final int MAXIMUM_CAPACITY = 1 << 30;  

  // 默认初始值，必须是2的幂数  
  private static final int DEFAULT_CAPACITY = 6;  

  // 数组可能最大值，需要与toArray（）相关方法关联  
  static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;  

  // 并发级别，遗留下来的，为兼容以前的版本  
  private static final int DEFAULT_CONCURRENCY_LEVEL = 16;  

  // 负载因子  
  private static final float LOAD_FACTOR = 0.75f;  

  // 链表转红黑树阀值,> 8 链表转换为红黑树  
  static final int TREEIFY_THRESHOLD = 8;  

  // 树转链表阀值，小于等于6  
  static final int UNTREEIFY_THRESHOLD = 6;  
 
 // 可被树化的最小表容量：64
  static final int MIN_TREEIFY_CAPACITY = 64;  

  private static final int MIN_TRANSFER_STRIDE = 16;  

  private static int RESIZE_STAMP_BITS = 16;  

  // 2^15-1，help resize的最大线程数  
  private static final int MAX_RESIZERS = (1 << (32 - RESIZE_STAMP_BITS)) - 1; 

  // 32-16=16，sizeCtl中记录size大小的偏移量  
  private static final int RESIZE_STAMP_SHIFT = 32 - RESIZE_STAMP_BITS;

  // forwarding nodes的hash值  
  static final int MOVED     = -1 ;  

  // 树根节点的hash值  
  static final int TREEBIN   = -2;  

  // ReservationNode的hash值  
  static final int RESERVED  = -3;  

  // 可用处理器数量  
  static final int NCPU = Runtime.getRuntime().availableProcessors();  

  // 存放node的数组  
  transient volatile Node<K,V>[] table;  

 /**
  * 控制标识符，用来控制table的初始化和扩容的操作，不同的值有不同的含义  
  * 当为负数时：-1 代表正在初始化，-N代表有N-1个线程正在进行扩容  
  * 当为0时：代表当时的table还没有被初始化  
  * 当为正数时：表示初始化或者下一次进行扩容的大小  
  */
  private transient volatile int sizeCtl;  

```

- 构造方法
```
// 空的构造
public ConcurrentHashMapDebug() {
}

// 如果在实例化对象的时候指定了容量，则初始化sizeCtl
public ConcurrentHashMapDebug(int initialCapacity) {
    if (initialCapacity < 0)
        throw new IllegalArgumentException();
    int cap = ((initialCapacity >= (MAXIMUM_CAPACITY >>> 1)) ?
               MAXIMUM_CAPACITY :
               tableSizeFor(initialCapacity + (initialCapacity >>> 1) + 1));
    this.sizeCtl = cap;
}

// 当出入一个Map的时候，先设定sizeCtl为默认容量，在添加元素
public ConcurrentHashMapDebug(Map<? extends K, ? extends V> m) {
    this.sizeCtl = DEFAULT_CAPACITY;
    putAll(m);
}

// 指定初始化大小以及负载因子构造方法
public ConcurrentHashMap(int initialCapacity, float loadFactor) {
    this(initialCapacity, loadFactor, 1);
}

/**
 *  指定初始化大小、负载因子以及允许并发修改线程数构造方法
 */
public ConcurrentHashMap(int initialCapacity,
                         float loadFactor, int concurrencyLevel) {
    if (!(loadFactor > 0.0f) || initialCapacity < 0 || concurrencyLevel <= 0)
        throw new IllegalArgumentException();
    if (initialCapacity < concurrencyLevel)   // Use at least as many bins
        initialCapacity = concurrencyLevel;   // as estimated threads
    long size = (long)(1.0 + (long)initialCapacity / loadFactor);
    int cap = (size >= (long)MAXIMUM_CAPACITY) ?
        MAXIMUM_CAPACITY : tableSizeFor((int)size);
    this.sizeCtl = cap;
}
```

> 可以看到，任何一个构造方法都没有对 table数组进行初始化。其实 table的初始化是再第一次put操作时进行的，那我们来看看初始化方法。

```
/**
 * 初始化数组table，
 * 如果sizeCtl小于0，说明别的数组正在进行初始化，则让出执行权
 * 如果sizeCtl大于0的话，则初始化一个大小为sizeCtl的数组
 * 否则的话初始化一个默认大小(16)的数组
 * 然后设置sizeCtl的值为数组长度的3/4
 */
private final Node<K,V>[] initTable() {
    Node<K,V>[] tab; int sc;
    while ((tab = table) == null || tab.length == 0) {  
        // 第一次put的时候，table还没被初始化，进入while
        if ((sc = sizeCtl) < 0)                            
        /**
         *  sizeCtl初始值为0，
         *  当小于0的时候表示在别的线程在初始化表或扩展表 Thread.yield();
         */
        // lost initialization race; just spin
        else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {    
            /**
             * SIZECTL：表示当前对象的内存偏移量，
             * sc表示期望值，
             * -1表示要替换的值，设定为-1表示要初始化表了
             */
            try {
                if ((tab = table) == null || tab.length == 0) {
                    int n = (sc > 0) ? sc : DEFAULT_CAPACITY;       
                 // 指定了大小的时候就创建指定大小的Node数组，否则创建指定大小(16)的Node数组
                    @SuppressWarnings("unchecked")
                    Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
                    table = tab = nt;
                    sc = n - (n >>> 2);
                }
            } finally {
                sizeCtl = sc;            
                // 初始化后，sizeCtl长度为数组长度的3/4
            }
            break;
        }
    }
    return tab;
}
```

- 存储方法

 1.  put 方法

     ```java
     /**
      *  单纯的调用putVal方法，并且putVal的第三个参数设置为false
      *  当设置为false的时候表示这个value一定会设置
      *  true的时候，只有当这个key的value为空的时候才会设置
      */
     public V put(K key, V value) {
     	return putVal(key, value, false);
     }
     
     /**
      * 当添加一对键值对的时候，首先会去判断保存这些键值对的数组是不是初始化了，
      * 如果没有的话就初始化数组
      *  然后通过计算hash值来确定放在数组的哪个位置
      * 如果这个位置为空则直接添加，如果不为空的话，则取出这个节点来
      * 如果取出来的节点的hash值是MOVED(-1)的话，则表示当前正在对这个数组进行扩容，复制到新的数组，则当前线程也去帮助复制
      * 最后一种情况就是，如果这个节点，不为空，也不在扩容，则通过synchronized来加锁，进行添加操作
      *    然后判断当前取出的节点位置存放的是链表还是树
      *    如果是链表的话，则遍历整个链表，直到取出来的节点的key来个要放的key进行比较，如果key相等，并且key的hash值也相等的话，
      *          则说明是同一个key，则覆盖掉value，否则的话则添加到链表的末尾
      *    如果是树的话，则调用putTreeVal方法把这个元素添加到树中去
      *  最后在添加完成之后，会判断在该节点处共有多少个节点（注意是添加前的个数），如果达到8个以上了的话，
      *  则调用treeifyBin方法来尝试将处的链表转为树，或者扩容数组
      */
     final V putVal(K key, V value, boolean onlyIfAbsent) {
         if (key == null || value == null) throw new NullPointerException();// K,V都不能为空，否则的话跑出异常
         int hash = spread(key.hashCode());    // 取得key的hash值
         int binCount = 0;    // 用来计算在这个节点总共有多少个元素，用来控制扩容或者转移为树
         for (Node<K,V>[] tab = table;;) {    //
             Node<K,V> f; int n, i, fh;
             if (tab == null || (n = tab.length) == 0)    
                 tab = initTable();    // 第一次put的时候table没有初始化，则初始化table
             else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {    
                 // 通过哈希计算出一个表中的位置因为n是数组的长度，所以(n-1)&hash肯定不会出现数组越界
                 if (casTabAt(tab, i, null,        //如 果这个位置没有元素的话，则通过cas的方式尝试添加，注意这个时候是没有加锁的
                              new Node<K,V>(hash, key, value, null)))        //创建一个Node添加到数组中区，null表示的是下一个节点为空
                     break;                   // no lock when adding to empty bin
             }
                 /*
                  * 如果检测到某个节点的hash值是MOVED，则表示正在进行数组扩张的数据复制阶段，
                  * 则当前线程也会参与去复制，通过允许多线程复制的功能，一次来减少数组的复制所带来的性能损失
                  */
             else if ((fh = f.hash) == MOVED)    
                 tab = helpTransfer(tab, f);
             else {
                     /*
                      * 如果在这个位置有元素的话，就采用synchronized的方式加锁，
                      *     如果是链表的话(hash大于0)，就对这个链表的所有元素进行遍历，
                      *         如果找到了key和key的hash值都一样的节点，则把它的值替换到
                      *         如果没找到的话，则添加在链表的最后面
                      *  否则，是树的话，则调用putTreeVal方法添加到树中去
                      *  
                      *  在添加完之后，会对该节点上关联的的数目进行判断，
                      *  如果在8个以上的话，则会调用treeifyBin方法，来尝试转化为树，或者是扩容
                      */
                 V oldVal = null;
                 synchronized (f) {
                     if (tabAt(tab, i) == f) {        // 再次取出要存储的位置的元素，跟前面取出来的比较
                         if (fh >= 0) {                // 取出来的元素的hash值大于0，当转换为树之后，hash值为-2
                             binCount = 1;            
                             for (Node<K,V> e = f;; ++binCount) {    // 遍历这个链表
                                 K ek;
                                 // 要存的元素的hash，key跟要存储的位置的节点的相同的时候，替换掉该节点的value即可
                                 if (e.hash == hash &&        
                                     ((ek = e.key) == key ||
                                      (ek != null && key.equals(ek)))) {
                                     oldVal = e.val;
                                     if (!onlyIfAbsent)        // 当使用putIfAbsent的时候，只有在这个key没有设置值得时候才设置
                                         e.val = value;
                                     break;
                                 }
                                 Node<K,V> pred = e;
                                 if ((e = e.next) == null) {    // 如果不是同样的hash，同样的key的时候，则判断该节点的下一个节点是否为空，
                                     pred.next = new Node<K,V>(hash, key,        // 为空的话把这个要加入的节点设置为当前节点的下一个节点
                                                               value, null);
                                     break;
                                 }
                             }
                         }
                         else if (f instanceof TreeBin) {    // 表示已经转化成红黑树类型了
                             Node<K,V> p;
                             binCount = 2;
                             // 调用putTreeVal方法，将该元素添加到树中去
                             if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key, value)) != null) {
                                 oldVal = p.val;
                                 if (!onlyIfAbsent)
                                     p.val = value;
                             }
                         }
                     }
                 }
                 if (binCount != 0) {
                     if (binCount >= TREEIFY_THRESHOLD)   
                         // 当在同一个节点的数目达到8个的时候，则扩张数组或将给节点的数据转为tree
                         treeifyBin(tab, i);    
                     if (oldVal != null)
                         return oldVal;
                     break;
                 }
             }
         }
         addCount(1L, binCount);    // 计数
         return null;
     }
     ```

     > 扩容解析

     * 同一个节点的个数超过 `8` 个的时候，会调用  `treeifyBin` 方法来看看是扩容还是转化为一棵树

     * 每次添加完元素的 `addCount` 方法中，也会判断当前数组中的元素是否达到了 `sizeCtl` 的量，若达到则调用 `transfer`去扩容

     ```java
     /**
      * 当数组长度小于64的时候，扩张数组长度一倍，否则的话把链表转为树
      */
     private final void treeifyBin(Node<K,V>[] tab, int index) {
         Node<K,V> b; int n, sc;
         if (tab != null) {
             System.out.println("treeifyBin方\t==>数组长："+tab.length);
             if ((n = tab.length) < MIN_TREEIFY_CAPACITY)    // MIN_TREEIFY_CAPACITY 64
                 tryPresize(n << 1);   // 数组扩容
             else if ((b = tabAt(tab, index)) != null && b.hash >= 0) {
                 synchronized (b) {    // 使用synchronized同步器，将该节点出的链表转为树
                     if (tabAt(tab, index) == b) {
                         TreeNode<K,V> hd = null, tl = null;    // hd：树的头(head)
                         for (Node<K,V> e = b; e != null; e = e.next) {
                             TreeNode<K,V> p =
                                 new TreeNode<K,V>(e.hash, e.key, e.val,
                                                   null, null);
                             if ((p.prev = tl) == null)   // 把Node组成的链表，转化为TreeNode的链表，头结点任然放在相同的位置
                                 hd = p;    // 设置head
                             else
                                 tl.next = p;
                             tl = p;
                         }
                         setTabAt(tab, index, new TreeBin<K,V>(hd));// 把TreeNode的链表放入容器TreeBin中
                     }
                 }
             }
         }
     }
     
     /**
      *  扩容表为指可以容纳指定个数的大小（总是2的N次方）
      *  假设原来的数组长度为16，则在调用tryPresize的时候，size参数的值为16<<1(32)，此时sizeCtl的值为12
      *  计算出来c的值为64,则要扩容到sizeCtl≥为止
      *    第一次扩容之后 数组长：32 sizeCtl：24
      *    第二次扩容之后 数组长：64 sizeCtl：48
      *    第二次扩容之后 数组长：128 sizeCtl：94 --> 这个时候才会退出扩容
      */
     private final void tryPresize(int size) {
            /*
             * MAXIMUM_CAPACITY = 1 << 30
             * 如果给定的大小大于等于数组容量的一半，则直接使用最大容量，
             * 否则使用tableSizeFor算出来
             * 后面table一直要扩容到这个值小于等于sizeCtrl(数组长度的3/4)才退出扩容
             */
         int c = (size >= (MAXIMUM_CAPACITY >>> 1)) ? MAXIMUM_CAPACITY :
         tableSizeFor(size + (size >>> 1) + 1);
         int sc;
         while ((sc = sizeCtl) >= 0) {
             Node<K,V>[] tab = table; int n;
             //            printTable(tab);    调试用的
                 /*
                  *  如果数组table还没有被初始化，则初始化一个大小为sizeCtrl和刚刚算出来的c中较大的一个大小的数组
                  *  初始化的时候，设置sizeCtrl为-1，初始化完成之后把sizeCtrl设置为数组长度的3/4
                  *  为什么要在扩张的地方来初始化数组呢？这是因为如果第一次put的时候不是put单个元素，
                  *  而是调用putAll方法直接put一个map的话，在putALl方法中没有调用initTable方法去初始化table，
                  *  而是直接调用了tryPresize方法，所以这里需要做一个是不是需要初始化table的判断
                  */
             if (tab == null || (n = tab.length) == 0) {
                 n = (sc > c) ? sc : c;
                 if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {    // 初始化tab的时候，把sizeCtl设为-1
                     try {
                         if (table == tab) {
                             @SuppressWarnings("unchecked")
                             Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
                             table = nt;
                             sc = n - (n >>> 2);
                         }
                     } finally {
                         sizeCtl = sc;
                     }
                 }
             }
                 /*
                  *  一直扩容到的c小于等于sizeCtl或者数组长度大于最大长度的时候，则退出
                  *  所以在一次扩容之后，不是原来长度的两倍，而是2的n次方倍
                  */
             else if (c <= sc || n >= MAXIMUM_CAPACITY) {
                 break;    // 退出扩容
             }
             else if (tab == table) {
                 int rs = resizeStamp(n);
                     /*
                      *  如果正在扩容Table的话，则帮助扩容
                      *  否则的话，开始新的扩容
                      *  在transfer操作，将第一个参数的table中的元素，移动到第二个元素的table中去，
                      *  虽然此时第二个参数设置的是null，但是，在transfer方法中，当第二个参数为null的时候，
                      *  会创建一个两倍大小的table
                      */
                 if (sc < 0) {
                     Node<K,V>[] nt;
                     if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||
                         sc == rs + MAX_RESIZERS || (nt = nextTable) == null ||
                         transferIndex <= 0)
                         break;
                         /*
                          *  transfer的线程数加一,该线程将进行transfer的帮忙
                          *  在transfer的时候，sc表示在transfer工作的线程数
                          */
                     if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1))
                         transfer(tab, nt);
                 }
                     /*
                      *  没有在初始化或扩容，则开始扩容
                      */
                 else if (U.compareAndSwapInt(this, SIZECTL, sc,
                                              (rs << RESIZE_STAMP_SHIFT) + 2)) {
                     transfer(tab, null);
                 }
             }
         }
     }
     
     /**
      *  把数组中的节点复制到新的数组的相同位置，或者移动到扩张部分的相同位置
      *  在这里首先会计算一个步长，表示一个线程处理的数组长度，用来控制对CPU的使用，
      *  每个CPU最少处理16个长度的数组元素,也就是说，如果一个数组的长度只有16，那只有一个线程会对其进行扩容的复制移动操作
      *  扩容的时候会一直遍历，知道复制完所有节点，没处理一个节点的时候会在链表的头部设置一个fwd节点，这样其他线程就会跳过他，
      *  复制后在新数组中的链表不是绝对的反序的
      */
     private final void transfer(Node<K,V>[] tab, Node<K,V>[] nextTab) {
         int n = tab.length, stride;
         if ((stride = (NCPU > 1) ? (n >>> 3) / NCPU : n) < MIN_TRANSFER_STRIDE)    // MIN_TRANSFER_STRIDE 用来控制不要占用太多CPU
             stride = MIN_TRANSFER_STRIDE; // subdivide range    //MIN_TRANSFER_STRIDE=16
             /*
              *  如果复制的目标nextTab为null的话，则初始化一个table两倍长的nextTab
              *  此时nextTable被设置值了(在初始情况下是为null的)
              *  因为如果有一个线程开始了表的扩张的时候，其他线程也会进来帮忙扩张，
              *  而只是第一个开始扩张的线程需要初始化下目标数组
              */
         if (nextTab == null) {            // initiating
             try {
                 @SuppressWarnings("unchecked")
                 Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n << 1];
                 nextTab = nt;
             } catch (Throwable ex) {      // try to cope with OOME
                 sizeCtl = Integer.MAX_VALUE;
                 return;
             }
             nextTable = nextTab;
             transferIndex = n;
         }
         int nextn = nextTab.length;
         /*
          *  创建一个fwd节点，这个是用来控制并发的，当一个节点为空或已经被转移之后，就设置为fwd节点
          *  这是一个空的标志节点
          */
         ForwardingNode<K,V> fwd = new ForwardingNode<K,V>(nextTab);
         boolean advance = true;    // 是否继续向前查找的标志位
         boolean finishing = false; // to ensure sweep(清扫) before committing nextTab,在完成之前重新在扫描一遍数组，看看有没完成的没
         for (int i = 0, bound = 0;;) {
             Node<K,V> f; int fh;
             while (advance) {
                 int nextIndex, nextBound;
                 if (--i >= bound || finishing) {
                     advance = false;
                 }
                 else if ((nextIndex = transferIndex) <= 0) {
                     i = -1;
                     advance = false;
                 }
                 else if (U.compareAndSwapInt
                          (this, TRANSFERINDEX, nextIndex,
                           nextBound = (nextIndex > stride ?
                                        nextIndex - stride : 0))) {
                     bound = nextBound;
                     i = nextIndex - 1;
                     advance = false;
                 }
             }
             if (i < 0 || i >= n || i + n >= nextn) {
                 int sc;
                 if (finishing) {        // 已经完成转移
                     nextTable = null;
                     table = nextTab;
                     sizeCtl = (n << 1) - (n >>> 1);    // 设置sizeCtl为扩容后的0.75
                     return;
                 }
                 if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) {
                     if ((sc - 2) != resizeStamp(n) << RESIZE_STAMP_SHIFT) {
                         return;
                     }
                     finishing = advance = true;
                     i = n; // recheck before commit
                 }
             }
             else if ((f = tabAt(tab, i)) == null)         // 数组中把null的元素设置为ForwardingNode节点(hash值为MOVED[-1])
                 advance = casTabAt(tab, i, null, fwd);
             else if ((fh = f.hash) == MOVED)
                 advance = true; // already processed
             else {
                 synchronized (f) {                // 加锁操作
                     if (tabAt(tab, i) == f) {
                         Node<K,V> ln, hn;
                         if (fh >= 0) {        // 该节点的hash值大于等于0，说明是一个Node节点
                             /*
                              *  因为n的值为数组的长度，且是power(2,x)的，所以，在&操作的结果只可能是0或者n
                              *  根据这个规则
                              *         0-->  放在新表的相同位置
                              *         n-->  放在新表的（n+原来位置）
                              */
                             int runBit = fh & n; 
                             Node<K,V> lastRun = f;
                             /*
                              *  lastRun 表示的是需要复制的最后一个节点
                              *  每当新节点的hash&n -> b 发生变化的时候，就把runBit设置为这个结果b
                              *  这样for循环之后，runBit的值就是最后不变的hash&n的值
                              *  而lastRun的值就是最后一次导致hash&n 发生变化的节点(假设为p节点)
                              *  为什么要这么做呢？因为p节点后面的节点的hash&n 值跟p节点是一样的，
                              *  所以在复制到新的table的时候，它肯定还是跟p节点在同一个位置
                              *  在复制完p节点之后，p节点的next节点还是指向它原来的节点，就不需要进行复制了，自己就被带过去了
                              *  这也就导致了一个问题就是复制后的链表的顺序并不一定是原来的倒序
                              */
                             for (Node<K,V> p = f.next; p != null; p = p.next) {
                                 int b = p.hash & n;    // n的值为扩张前的数组的长度
                                 if (b != runBit) {
                                     runBit = b;
                                     lastRun = p;
                                 }
                             }
                             if (runBit == 0) {
                                 ln = lastRun;
                                 hn = null;
                             }
                             else {
                                 hn = lastRun;
                                 ln = null;
                             }
                             /*
                              *  构造两个链表，顺序大部分和原来是反的
                              *  分别放到原来的位置和新增加的长度的相同位置(i/n+i)
                              */
                             for (Node<K,V> p = f; p != lastRun; p = p.next) {
                                 int ph = p.hash; K pk = p.key; V pv = p.val;
                                 if ((ph & n) == 0)
                                     /*
                                      *  假设runBit的值为0，
                                      *  则第一次进入这个设置的时候相当于把旧的序列的最后一次发生hash变化的节点(该节点后面可能还有hash计算后同为0的节点)设置到旧的table的第一个hash计算后为0的节点下一个节点
                                      *  并且把自己返回，然后在下次进来的时候把它自己设置为后面节点的下一个节点
                                      */
                                     ln = new Node<K,V>(ph, pk, pv, ln);
                                 else
                                     /*
                                      *  假设runBit的值不为0，
                                      *  则第一次进入这个设置的时候相当于把旧的序列的最后一次发生hash变化的节点(该节点后面可能还有hash计算后同不为0的节点)设置到旧的table的第一个hash计算后不为0的节点下一个节点
                                      *  并且把自己返回，然后在下次进来的时候把它自己设置为后面节点的下一个节点
                                      */
                                     hn = new Node<K,V>(ph, pk, pv, hn);    
                             }
                             setTabAt(nextTab, i, ln);    
                             setTabAt(nextTab, i + n, hn);
                             setTabAt(tab, i, fwd);
                             advance = true;
                         }
                         else if (f instanceof TreeBin) {    // 否则的话是一个树节点
                             TreeBin<K,V> t = (TreeBin<K,V>)f;
                             TreeNode<K,V> lo = null, loTail = null;
                             TreeNode<K,V> hi = null, hiTail = null;
                             int lc = 0, hc = 0;
                             for (Node<K,V> e = t.first; e != null; e = e.next) {
                                 int h = e.hash;
                                 TreeNode<K,V> p = new TreeNode<K,V>
                                     (h, e.key, e.val, null, null);
                                 if ((h & n) == 0) {
                                     if ((p.prev = loTail) == null)
                                         lo = p;
                                     else
                                         loTail.next = p;
                                     loTail = p;
                                     ++lc;
                                 }
                                 else {
                                     if ((p.prev = hiTail) == null)
                                         hi = p;
                                     else
                                         hiTail.next = p;
                                     hiTail = p;
                                     ++hc;
                                 }
                             }
                             /*
                              *  在复制完树节点之后，判断该节点处构成的树还有几个节点，
                              *  如果≤6个的话，就转回为一个链表
                              */
                             ln = (lc <= UNTREEIFY_THRESHOLD) ? untreeify(lo) :
                             (hc != 0) ? new TreeBin<K,V>(lo) : t;
                             hn = (hc <= UNTREEIFY_THRESHOLD) ? untreeify(hi) :
                             (lc != 0) ? new TreeBin<K,V>(hi) : t;
                             setTabAt(nextTab, i, ln);
                             setTabAt(nextTab, i + n, hn);
                             setTabAt(tab, i, fwd);
                             advance = true;
                         }
                     }
                 }
             }
         }
     }
     ```

     **到这里，`ConcurrentHashMap` 的 `put操作` 和`扩容操作` 基本上介绍完毕。**

 2. get 方法

     ```java
     /*
      *  相比put方法，get就很单纯了，支持并发操作，
      *  当key为null的时候回抛出NullPointerException的异常
      *  get操作通过首先计算key的hash值来确定该元素放在数组的哪个位置
      *  然后遍历该位置的所有节点
      *  如果不存在的话返回null
      */
     public V get(Object key) {
         Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek;
         int h = spread(key.hashCode());
         if ((tab = table) != null && (n = tab.length) > 0 &&
             (e = tabAt(tab, (n - 1) & h)) != null) {
             if ((eh = e.hash) == h) { // 哈希值相等
                 if ((ek = e.key) == key || (ek != null && key.equals(ek))) // key相等
                     return e.val; // 则返回
             }
             else if (eh < 0)
                 return (p = e.find(h, key)) != null ? p.val : null;
             while ((e = e.next) != null) {
                 if (e.hash == h &&
                     ((ek = e.key) == key || (ek != null && key.equals(ek))))
                     return e.val;
             }
         }
         return null;
     }
     ```

     > 其他操作方法基本上与 HashMap 类似，这里就不做详细介绍了。

- 同步机制

  **ConcurrentHashMap** 是线程安全的，那么它是如何做到并发情况下，如何做到同步的呢? 接下来，让我一步步来剖析下其是如何实现的.

  > 读操作

  读操作即（get 操作），根据上述源码解析，没有使用同步机制 ，也没有使用unsafe方法，所以读操作是支持并发操作的。

  > 写操作

  写操作即（put 操作 ），根据上面源码剖析，我们知道扩容最终是通过 `transfer` 方法进行的 ，而调用transfer方法的只有`trePresize` 、`helpTransfer` 和 `addCount` 三个方法。

  * tryPresize是在treeIfybin和putAll方法中调用，treeIfybin主要是在put添加元素完之后，判断该数组节点相关元素是不是已经超过8个的时候，如果超过则会调用这个方法来扩容数组或者把链表转为树。
  * helpTransfer是在当一个线程要对table中元素进行操作的时候，如果检测到节点的HASH值为MOVED的时候，就会调用helpTransfer方法，在helpTransfer中再调用transfer方法来帮助完成数组的扩容。
  * addCount是在当对数组进行操作，使得数组中存储的元素个数发生了变化的时候会调用的方法。

  **引起数组扩容的情况？**

     - 只有在往map中添加元素的时候，在某一个节点的数目已经超过了8个，同时数组的长度又小于64的时候，才会触发数组的扩容
     - 当数组中元素达到了sizeCtl的数量的时候，则会调用transfer方法来进行扩容

  **在扩容的时候，可以不可以对数组进行读写操作呢？**

     事实上是可以的。
     - 当扩容时，如果当前节点还没有被处理（也就是说还没有设置为fwd节点），那就可以进行设置操作。
     - 当扩容时，如果该节点已经被处理了，则当前线程也会加入到扩容的操作中去。

  **多线程又是如何同步处理的呢？**

     在`ConcurrentHashMap`中，同步处理主要是通过 `Synchronized` 和 `unsafe` 两种方式来完成的。

     - 在取得sizeCtl、某个位置的Node的时候，使用的都是unsafe的方法，来达到并发安全的目的。
     - 当需要在某个位置设置节点的时候，则会通过Synchronized的同步机制来锁定该位置的节点。
     - 在数组扩容的时候，则通过处理的步长和fwd节点来达到并发安全的目的，通过设置hash值为MOVED。
     - 当把某个位置的节点复制到扩张后的table的时候，也通过Synchronized的同步机制来保证现程安全。

**综上所述，`ConcurrentHashMap` 基本上介绍完毕，希望对大家有所帮助！！！**

------
> 文章可以白嫖，老铁们顺便关注一下我的公众号，手动滑稽🤣🤣 &nbsp;
>
> 欢迎大家关注：**武哥聊编程**、**Java开发宝典**、**Java秃头哥**，您的支持，是我创作的持续动力！&nbsp;&nbsp;

![公众号二维码](https://img-blog.csdnimg.cn/20201121225359995.png)